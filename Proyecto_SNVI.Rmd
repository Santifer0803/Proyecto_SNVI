---
title: "Proyecto SNV1"
author: "Alejandro Brenes, Santiago Fernández, Eyeri Méndez y Erick Venegas"
date: "`r Sys.Date()`"
output: html_document
---

# Introducción

Se cargan las librerías necesarias.

```{r librerias}
# Si no funciona descargar caret, usen lo siguiente:

# options(repos = c(CRAN = "https://cloud.r-project.org"))
# remove.packages(c("future", "future.apply", "parallelly", "recipes"))
# install.packages(c("parallelly", "future", "future.apply", "recipes", "caret"), type = "binary")
pacman::p_load(ggplot2,
               readxl,
               cowplot,
               dplyr,
               tidyr,
               corrplot,
               future.apply,
               caret,
               xgboost,
               pROC)
```

Se lee la base de incendios forestales en Argelia.

```{r base_incendios}
# Bases de datos
incendios.B <- read_excel("data/Incendios.xlsx", sheet = "Bejaia")
incendios.SB <- read_excel("data/Incendios.xlsx", sheet = "Bejaia")

# Se juntan las bases
incendios <- rbind(incendios.B, incendios.SB)

# Se cambia el nombre de las categorías de la variable Classes
incendios$Classes <- factor(
  incendios$Classes,
  levels = c("not fire", "fire"),
  labels = c("Sin incendio", "Con incendio")
)
```

# Resumen descriptivo y análisis de correlación

Como primer paso, se calculan algunas estadísticas descriptivas tanto para cuando ocurrió un incendio como para cuando no. 

```{r filtrar.incendios}
dias.con.incendios <- subset(incendios, Classes == "Con incendio")
dias.con.incendios <- dias.con.incendios[, -14]

dias.sin.incendios <- subset(incendios, Classes == "Sin incendio")
dias.sin.incendios <- dias.sin.incendios[, -14]
```

```{r resumen.con.incendios}
incendios.pivot <- dias.con.incendios %>%
  pivot_longer(cols = everything(),
               names_to = "variable",
               values_to = "valor")

resumen.incendios <- incendios.pivot %>%
  group_by(variable) %>%
  summarise(
    promedio = mean(valor, na.rm = TRUE),
    minimo = min(valor, na.rm = TRUE),
    mediana = median(valor, na.rm = TRUE),
    maximo = max(valor, na.rm = TRUE),
    desviacion = sd(valor, na.rm = TRUE)
  )
```

```{r resumen.sin.incendios}
sin.incendios.pivot <- dias.sin.incendios %>%
  pivot_longer(cols = everything(),
               names_to = "variable",
               values_to = "valor")

resumen.sin.incendios <- sin.incendios.pivot %>%
  group_by(variable) %>%
  summarise(
    promedio = mean(valor, na.rm = TRUE),
    minimo = min(valor, na.rm = TRUE),
    mediana = median(valor, na.rm = TRUE),
    maximo = max(valor, na.rm = TRUE),
    desviacion = sd(valor, na.rm = TRUE)
  )
```

Posteriormente, se realizan gráficos de correlaciones tanta cuando hubo incendio como para cuando no.

```{r correlaciones, fig.width=12, fig.height=10}
# Correlación de los dias con incendios
cor.incendios <- cor(dias.con.incendios[, apply(dias.con.incendios, 2, var, na.rm = TRUE) != 0], dias.con.incendios[, apply(dias.con.incendios, 2, var, na.rm = TRUE) != 0]) # Solo valores con varianza mayor a 0

corrplot(
  cor.incendios,
  method = "color",
  type = "upper",
  order = "hclust",
  addCoef.col = "black",
  number.cex = 0.7,
  number.digits = 3
)

# Correlación de los dias sin incendios
cor.sin.incendios <- cor(dias.sin.incendios[, apply(dias.sin.incendios, 2, var, na.rm = TRUE) != 0], dias.sin.incendios[, apply(dias.sin.incendios, 2, var, na.rm = TRUE) != 0]) # Solo valores con varianza mayor a 0

corrplot(
  cor.sin.incendios,
  method = "color",
  type = "upper",
  order = "hclust",
  addCoef.col = "black",
  number.cex = 0.7,
  number.digits = 3
)
```
Ahora las correlaciones sin incluir las fecha

```{r correlaciones.nf, fig.width=12, fig.height=10}
dias.con.incendios.nf <- dias.con.incendios[, -c(1,2,3)]
dias.sin.incendios.nf <- dias.sin.incendios[, -c(1,2,3)]


cor.sin.incendios.nf <- cor(dias.sin.incendios.nf[, apply(dias.sin.incendios.nf, 2, var, na.rm = TRUE) != 0], dias.sin.incendios.nf[, apply(dias.sin.incendios.nf, 2, var, na.rm = TRUE) != 0]) # Solo valores con varianza mayor a 0

corrplot(
  cor.sin.incendios.nf,
  method = "color",
  type = "upper",
  order = "hclust",
  addCoef.col = "black",
  number.cex = 0.7,
  number.digits = 3
)

cor.con.incendios.nf <- cor(dias.con.incendios.nf[, apply(dias.con.incendios.nf, 2, var, na.rm = TRUE) != 0], dias.con.incendios.nf[, apply(dias.con.incendios.nf, 2, var, na.rm = TRUE) != 0]) # Solo valores con varianza mayor a 0

corrplot(
  cor.con.incendios.nf,
  method = "color",
  type = "upper",
  order = "hclust",
  addCoef.col = "black",
  number.cex = 0.7,
  number.digits = 3
)
```



# Gráficos entre variables

Se procede a realizar distintos gráficos entre los valores de las variables presentes en la base.
Paara esto, se usa como referencia el apartado anterior, graficando solo variables que tengan una correlación mayor a 0.5 (con algunas excepciones).

## Variables vs. FFMC

```{r Variables_FFMC}
# DMC vs. FFMMC
ggplot(incendios, aes(x = FFMC, y = DMC, color = Classes)) +
  geom_point() +
  labs(x = "FFMC",
       y = "DMC",
       color = "") +
  theme_cowplot()

# DC vs. FFMMC
ggplot(incendios, aes(x = FFMC, y = DC, color = Classes)) +
  geom_point() +
  labs(x = "FFMC",
       y = "DC",
       color = "") +
  theme_cowplot()

# ISI vs. FFMMC
ggplot(incendios, aes(x = FFMC, y = ISI, color = Classes)) +
  geom_point() +
  labs(x = "FFMC",
       y = "ISI",
       color = "") +
  theme_cowplot()

# BUI vs. FFMMC
ggplot(incendios, aes(x = FFMC, y = BUI, color = Classes)) +
  geom_point() +
  labs(x = "FFMC",
       y = "BUI",
       color = "") +
  theme_cowplot()

# FWI vs. FFMMC
ggplot(incendios, aes(x = FFMC, y = FWI, color = Classes)) +
  geom_point() +
  labs(x = "FFMC",
       y = "FWI",
       color = "") +
  theme_cowplot()

# Temperatura vs. FFMMC
ggplot(incendios, aes(x = FFMC, y = Temperature, color = Classes)) +
  geom_point() +
  labs(x = "FFMC",
       y = "Temperatura",
       color = "") +
  theme_cowplot()

# RH vs. FFMMC
ggplot(incendios, aes(x = FFMC, y = RH, color = Classes)) +
  geom_point() +
  labs(x = "FFMC",
       y = "RH",
       color = "") +
  theme_cowplot()

# Lluvia vs. FFMMC
ggplot(incendios, aes(x = FFMC, y = Rain, color = Classes)) +
  geom_point() +
  labs(x = "FFMC",
       y = "Lluvia",
       color = "") +
  theme_cowplot()
```

## ISI y Temperatura vs. RH

```{r RH_Rain_FFMC}
# ISI vs. RH
ggplot(incendios, aes(x = RH, y = ISI, color = Classes)) +
  geom_point() +
  labs(x = "RH",
       y = "ISI",
       color = "") +
  theme_cowplot()

# Temperatura vs. RH
ggplot(incendios, aes(x = RH, y = Temperature, color = Classes)) +
  geom_point() +
  labs(x = "RH",
       y = "Temperatura",
       color = "") +
  theme_cowplot()
```

## Variables vs. FWI

```{r Variables_FWI}
# DC vs. FWI
ggplot(incendios, aes(x = FWI, y = DC, color = Classes)) +
  geom_point() +
  labs(x = "FWI",
       y = "DC",
       color = "") +
  theme_cowplot()

# DMC vs. FWI
ggplot(incendios, aes(x = FWI, y = DMC, color = Classes)) +
  geom_point() +
  labs(x = "FWI",
       y = "DMC",
       color = "") +
  theme_cowplot()

# BUI vs. FWI
ggplot(incendios, aes(x = FWI, y = BUI, color = Classes)) +
  geom_point() +
  labs(x = "FWI",
       y = "BUI",
       color = "") +
  theme_cowplot()

# Temperatura vs. FWI
ggplot(incendios, aes(x = FWI, y = Temperature, color = Classes)) +
  geom_point() +
  labs(x = "FWI",
       y = "Temperatura",
       color = "") +
  theme_cowplot()

# ISI vs. FWI
ggplot(incendios, aes(x = FWI, y = ISI, color = Classes)) +
  geom_point() +
  labs(x = "FWI",
       y = "ISI",
       color = "") +
  theme_cowplot()
```

## Variables vs. DC

```{r Vaiables_DC}
# BUI vs. DC
ggplot(incendios, aes(x = DC, y = BUI, color = Classes)) +
  geom_point() +
  labs(x = "DC",
       y = "BUI",
       color = "") +
  theme_cowplot()

# Temperatura vs. DC
ggplot(incendios, aes(x = DC, y = Temperature, color = Classes)) +
  geom_point() +
  labs(x = "DC",
       y = "Temperatura",
       color = "") +
  theme_cowplot()

# ISI vs. DC
ggplot(incendios, aes(x = DC, y = ISI, color = Classes)) +
  geom_point() +
  labs(x = "DC",
       y = "ISI",
       color = "") +
  theme_cowplot()
```

## ISI y BUI vs. DMC

```{r ISI_BUI_DMC}
# ISI vs. DMC
ggplot(incendios, aes(x = DMC, y = ISI, color = Classes)) +
  geom_point() +
  labs(x = "DMC",
       y = "ISI",
       color = "") +
  theme_cowplot()

# BUI vs. DMC
ggplot(incendios, aes(x = DMC, y = BUI, color = Classes)) +
  geom_point() +
  labs(x = "DMC",
       y = "BUI",
       color = "") +
  theme_cowplot()
```

# Ajuste de los modelos

## Separación de los datos

Debido a la poca cantidad de observaciones en las bases de datos, se realiza una separación 80/20 en los datos de *training* y *testing* respectivamente.

```{r separacion_datos}
# Semilla para reproducibilidad
set.seed(0609)

# Se cambia la variable objetivo a numérica, 1 significa que hubo incendio, 0 que no
incendios <- incendios %>% mutate(Classes = ifelse(Classes == "Con incendio", "Incendio", "No.incendio"))

# Se modifica la variable objetivo como factor
incendios$Classes <- factor(incendios$Classes, levels = c("Incendio", "No.incendio"))

# Se agrega una columna de id a la base de datos
incendios$id <- 1:nrow(incendios)

# Se pone de primera la variable de id
incendios <- incendios %>% select(id, colnames(incendios[, 1:ncol(incendios)]))

# Se obtienen los datos de training y testing
data.train <- incendios %>% sample_frac(0.8)
data.test <- anti_join(incendios, data.train, by = "id")
```


## Random forest

a

## XGBoost

Luego, nos centramos en el XGBoost. Para este caso usamos la librería [caret](https://topepo.github.io/caret/index.html) para obtener el ajuste. En particular, en el método del [XGBoost](https://www-geeksforgeeks-org.translate.goog/machine-learning/different-results-xgboost-vs-caret-in-r/?_x_tr_sl=en&_x_tr_tl=es&_x_tr_hl=es&_x_tr_pto=tc) que ofrece el paquete.

```{r ajuste_xgb}
# Lista para iteraciones
lista.ll <- list()
lista.int <- list()

# Para ver el número óptimo de iteraciones de validación cruzada, se prueban todos los valores del 1 al 10 y se compara con la pérdida logarítmica
for (i in 2:5) {
  # Ciclo para tomar en cuenta la variabilidad de las observaciones
  for (j in 1:10) {
    # Se define el control de entrenamiento, esto genera los parámetros que se usarán para el modelo.
    ## method: Método de remuestreo, en este caso, de validación cruzada
    ## number: Cantidad de pliegues de la validación cruzada (se puede graficar)
    ## verboseIter: Para imprimir (TRUE) el registro de entrenamiento
    ## classProbs: Define si se calculan las probabilidades para las muestras obtenidas del remuestreo
    ## selectionFunction: Permite definir los parámetros óptimos según una métrica. En este caso, para clasificación binaria
    ## returnResamp: Permite guardar los remuestreos
    ## allowParallel: Permite la paralelización
    control.entrenamiento <-
      trainControl(
        method = "cv",
        number = i,
        verboseIter = FALSE,
        classProbs = TRUE,
        summaryFunction = twoClassSummary
      )
    
    # Se define el modelo del XGBoost. Internamente tiene una variable desactualizada en caret, por lo que puede tirar un warning
    ## x: Variable objetivo (la que se busca predecir)
    ## data: Datos a utilizar (debe ser DataFrame)
    ## method: Método a utilizar, en este caso, XGBoost
    ## trControl: El objeto con los parámetros óptimos encontrados anteriormente
    ## metric: La métrica a optimizar. En este caso, la curva ROC
    modelo.xgb <- train(
      Classes ~ .,
      data = data.train,
      method = "xgbTree",
      trControl = control.entrenamiento,
      metric = "ROC",
      verbose = FALSE
    )
    
    # Se calcula la pérdida logarítmica. Primero se predicen las probabilidades con los datos de testing
    prediccion.xgb <-
      predict(modelo.xgb, newdata = data.test, type = "prob")
    
    # Se obtienen las observaciones que son incendios
    prob.incendio <- prediccion.xgb$Incendio
    
    # Vector binario para saber si la clase es incendio o no
    obs.incendio <- data.test$Classes == "Incendio"
    
    # Se corrigen las probabilidades de incendio con un epsilon, por los valores extremos de [0, 1]
    prob.incendio <- pmin(pmax(prob.incendio, 1e-15), 1 - 1e-15)
    
    # Se guardan las iteraciones con cada número de iteraciones
    lista.int[[j]] <- -mean(obs.incendio * log(prob.incendio) + (1 - obs.incendio) * log(1 - prob.incendio))
  }
  
  
  # Pérdida logarítmica
  lista.ll[[(i - 1)]] <- c(i, mean(unlist(lista.int)))
}

# Se pasan los resultados a un dataframe
df.logloss <- as.data.frame(do.call(rbind, lista.ll))

# Se cambian los nombres
colnames(df.logloss) <- c("iter", "logl")

# Se grafica cada resultado obtenido
ggplot(df.logloss, aes(x = iter, y = logl)) +
  geom_line(color = "#F8766D") +
  geom_point(color = "#F8766D",
             size = 3,
             shape = 16) +
  labs(x = "Cantidad de iteraciones",
       y = "Pérdida logarítmica") +
  theme_minimal()
```

Debido a que una pérdida logarítmica menor implica un mejor modelo, se seleccionó el modelo de validación cruzada con 3 iteraciones. 

```{r modelo_final}
# Se define el control de entrenamiento, esto genera los parámetros que se usarán para el modelo.
    ## method: Método de remuestreo, en este caso, de validación cruzada
    ## number: Cantidad de pliegues de la validación cruzada (se puede graficar)
    ## verboseIter: Para imprimir (TRUE) el registro de entrenamiento
    ## classProbs: Define si se calculan las probabilidades para las muestras obtenidas del remuestreo
    ## selectionFunction: Permite definir los parámetros óptimos según una métrica. En este caso, para clasificación binaria
    ## returnResamp: Permite guardar los remuestreos
    ## allowParallel: Permite la paralelización
    control.entrenamiento <-
      trainControl(
        method = "cv",
        number = 3,
        verboseIter = FALSE,
        classProbs = TRUE,
        summaryFunction = twoClassSummary
      )
    
    # Se define el modelo del XGBoost. Internamente tiene una variable desactualizada en caret, por lo que puede tirar un warning
    ## x: Variable objetivo (la que se busca predecir)
    ## data: Datos a utilizar (debe ser DataFrame)
    ## method: Método a utilizar, en este caso, XGBoost
    ## trControl: El objeto con los parámetros óptimos encontrados anteriormente
    ## metric: La métrica a optimizar. En este caso, la curva ROC
    modelo.xgb <- train(
      Classes ~ .,
      data = data.train,
      method = "xgbTree",
      trControl = control.entrenamiento,
      metric = "ROC",
      verbose = FALSE
    )
```


En este se pueden ver los parámetros óptimos del modelo, resultados del remuestreo, algunas métricas

```{r xgb_final}
modelo.xgb
```

En este caso, se pueden ver los parámetros óptimos del modelo, en donde:
  - nrounds: Es la cantidad de iteraciones (o árboles, en este caso) óptima.
  - max_depth: Es la complejidad (o profundidad del árbol) máxima.
  - eta (learning rate): Es un parámetro de que se usa para ajustar el modelo, este mejora la presición del algoritmo. En concreto, este indica la resistencia del modelo al sobreajuste. (https://primo-tc-na01.hosted.exlibrisgroup.com/primo-explore/fulldisplay?docid=TN_cdi_proquest_journals_2608081906&context=PC&vid=SIBDI&lang=es_CR&search_scope=sibdiucr_completo&adaptor=primo_central_multiple_fe&tab=sibdiucr_tab&query=any,contains,eta%20xgboost&offset=0)
  - gamma (min split loss): Es un parámetro que indica el aumento mínimo en la función objetivo (el ROC en este caso), para que el árbol se divida (https://xgboost.readthedocs.io/en/stable/parameter.html). Al ser 0, el algoritmo no es muy conservador. Además, este tiene un peso muy significativo en la predicción final del XGBoost (https://primo-tc-na01.hosted.exlibrisgroup.com/primo-explore/fulldisplay?docid=TN_cdi_acm_books_10_1145_3357254_3357290_brief&context=PC&vid=SIBDI&lang=es_CR&search_scope=sibdiucr_completo&adaptor=primo_central_multiple_fe&tab=sibdiucr_tab&query=any,contains,gamma%20xgboost&offset=0)

# Resultados

## Random forest

a

## XGBoost

En este punto, se muestran algunas de las metricas del modelo XGBoost.

Inicialmente, se puede apreciar uno de los árboles de decisión construidos, este corresponde a separar la variable objetivo en aquellas con un valor menor de $ISI \approx 2.6$ y aquellas con un valor mayor.

```{r arbol_xgb}
# Gráfico de un árbol de decisión
# xgb.plot.tree(model = modelo.xgb$finalModel, trees = 0)
```

Se procede a mostrar la [importancia](https://topepo.github.io/caret/variable-importance.html#an-example-2) de cada una de las variables en el modelo, esto en escala del 0 al 100.

```{r importancia_xgb}
# Se guarda la importancia de las variables
importancia <- varImp(modelo.xgb, scale = FALSE)

# Se deja solo el dataframe
importancia <- data.frame(variable = rownames(importancia[[1]]),
                          promedio_importancia = importancia[[1]][, 1])

# Se grafica lo anterior
ggplot(importancia, aes(x = reorder(variable, promedio_importancia), y = promedio_importancia)) +
  geom_bar(stat = "identity", fill = "#F8766D") +
  coord_flip() +
  labs(x = "Categoría", y = "Valor", title = "Gráfico de barras horizontal") +
  theme_cowplot()
```

Se procede con la curva ROC, que fue la métrica que se maximizó en este caso.

```{r roc_xgb}
# Se predicen las probabilidades con los datos de testing
prediccion.xgb <-
  predict(modelo.xgb, newdata = data.test, type = "prob")

# Curva ROC
roc.xgb <-
  roc(
    response = data.test$Classes,
    predictor = prediccion.xgb$Incendio,
    levels = c("Incendio", "No.incendio"),
    direction = ">"
  )

# Se grafica el ROC
plot(roc.xgb,
     col = "#F8766D",
     lwd = 2,
     legacy.axes = TRUE)

# Valor del AUC
auc(roc.xgb)

# Valor del índice de Gini
cat("Índice de Gini: ", 2 * auc(roc.xgb) - 1)
```

Se continúa con la matriz de confusión.

```{r matriz_conf_xgb}
# Cambiamos el tipo de predicción
prediccion.xgb <- predict(modelo.xgb, newdata = data.test)

# Se extrae la matriz de confusión
mat.conf.xgb <-
  confusionMatrix(prediccion.xgb, data.test$Classes, positive = "Incendio")

# Se pasa a data.frame
mat.conf.xgb <- as.data.frame(mat.conf.xgb$table)

# Se cambia a factor
mat.conf.xgb$Reference <-
  factor(mat.conf.xgb$Reference, levels = levels(data.test$Classes))
mat.conf.xgb$Prediction <-
  factor(mat.conf.xgb$Prediction, levels = c("No.incendio", "Incendio"))

# Se grafica lo anterior
ggplot(mat.conf.xgb, aes(x = Prediction, y = Reference, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Freq), size = 5, color = "black") +
  scale_fill_gradient(low = "white", high = "#F8766D") +
  labs(x = "Predicción",
       y = "Real") +
  theme_cowplot() +
  theme(legend.position = "none")
```

Se procede con las métricas derivadas de la matriz de confusión.

```{r metricas_xgb}
# Se recalcula la matriz de confusión, para tenerla en el formato correspondiente
mat.conf.xgb <-
  confusionMatrix(prediccion.xgb, data.test$Classes, positive = "Incendio")

# Métricas correspondientes
cat("La acurracy (exactitud) es: ", mat.conf.xgb$overall["Accuracy"], "\n")
cat("La sensibilidad es: ", mat.conf.xgb$byClass["Sensitivity"], "\n")
cat("La especificidad es: ", mat.conf.xgb$byClass["Specificity"], "\n")
cat("La precisión es: ", mat.conf.xgb$byClass["Precision"])
```

Finalmente, se tiene la pérdida logarítmica o log-loss.

```{r logloss_xgb}
# Se predicen las probabilidades con los datos de testing
prediccion.xgb <-
  predict(modelo.xgb, newdata = data.test, type = "prob")

# Se obtienen las observaciones que son incendios
prob.incendio <- prediccion.xgb$Incendio

# Vector binario para saber si la clase es incendio o no
obs.incendio <- data.test$Classes == "Incendio"

# Se corrigen las probabilidades de incendio con un epsilon, por los valores extremos de [0, 1]
prob.incendio <- pmin(pmax(prob.incendio, 1e-15), 1 - 1e-15)

# Pérdida logarítmica
log.loss <- -mean(obs.incendio * log(prob.incendio) + (1 - obs.incendio) * log(1 - prob.incendio))
cat("La pérdida logarítmica (log-loss) es: ", log.loss)
```

